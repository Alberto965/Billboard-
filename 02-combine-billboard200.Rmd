---
title: "Combine for current charts"
output:
  html_document:
    theme: flatly
    toc: true
    toc_depth: 3
    toc_float: true
    df_print: paged
knit: (function(inputFile, encoding) { rmarkdown::render(inputFile, encoding = encoding, output_dir = "../docs") })
---

## Goals of this notebook

This notebook builds an archive of [billboard 200]() charts going back in history. Weeks through the end of 2020 were build through a python script and manually updated. 2021 forward is done in an R scrape that should be automated at some ponit.

This notebook informs action scripts that will be built in the future. I need to decide if I should use the same Github Action scripts to do both Hot 100 and Billboard 200

## Setup

```{r setup, echo=T, results='hide', message=F, warning=F}
library(tidyverse)
library(fs)
```

## Import archive data

We are pulling in the previous Billboard 200 data and preparing it to meld with current data.

We rename some columns to match our newer data.

```{r import-archive}
charts_archive <- read_csv("data-out/billboard200.csv") %>%
  rename(
    chart_week = date,
    current_week = current,
    performer = artist,
    last_week = previous,
    peak_pos = peak,
    wks_on_chart = weeks
  ) |> 
  select(
    chart_week,
    current_week,
    title,
    performer,
    last_week,
    peak_pos,
    wks_on_chart
  )

charts_archive %>% glimpse()
```

## Get recent years

This reads in and combines all the data that I've scraped recently.

### Build a list of files to combine

Right now this would get everything inside `hot100-scraped`, including other yearly folders.

```{r files-list}
#### This requires the fs package
files_list <-  dir_ls("data-download/billboard200-scraped/", recurse = TRUE, regexp = ".csv")

#### A base R version
# files <- list.files(path = "data-download/hot100-scraped/2022/", pattern = "*.csv", full.names = T)

#### Peek at the list
files_list
```

### Combine files in the files_list

Of the many ways to do this, this is the sparsest code. Not sure what I would do if read_csv needed arguments. This uses the tidyverse purrr [map](https://purrr.tidyverse.org/reference/map.html) function.

```{r read-combine-recent}
# uses files_list from above
charts_recent <- map_dfr(files_list, read_csv, col_types = cols("last_week" = col_integer()))
```

Glimpse at the data

```{r recent-glimpse}
charts_recent %>% glimpse()
```

## Bind data sets together

Now to put the archives and recent charts together.

```{r combine-all}
charts_current <- charts_archive %>% 
  bind_rows(charts_recent)

charts_current %>% glimpse()
```


## Export

We'll export these combined files for public use?

```{r export}
charts_current %>% write_csv("data-out/billboard200_current.csv")
```

## Data smells

There are clearly some problems as the number of records is not divisible by 200. The problem is with the older data, but looking into where here.

```{r}
charts_current |> 
  count(chart_week) |> 
  filter(n != 200)
```


