---
title: "Combine for current charts"
output:
  html_document:
    theme: flatly
    toc: true
    toc_depth: 3
    toc_float: true
    df_print: paged
knit: (function(inputFile, encoding) { rmarkdown::render(inputFile, encoding = encoding, output_dir = "../docs") })
---

## Goals of this notebook

> IMPORTANT: This is superceded by 02-combine-charts.

This notebook builds an archive of [billboard 200]() charts going back in history. Weeks through the end of 2020 were build through a python script and manually updated. 2021 forward is done in an R scrape that should be automated at some ponit.

This notebook informs action scripts that will be built in the future. I need to decide if I should use the same Github Action scripts to do both Hot 100 and Billboard 200

## Setup

```{r setup, echo=T, results='hide', message=F, warning=F}
library(tidyverse)
library(fs)
library(lubridate)
```

## Import archive data

We are pulling in the previous Billboard 200 data and preparing it to meld with current data.

We rename some columns to match our newer data.

```{r import-archive}
charts_archive <- read_csv("data-out/billboard200.csv") |> 
    select(
      chart_week = date,
      current_week = current,
      title,
      performer = artist,
      last_week = previous,
      peak_pos = peak,
      wks_on_chart = weeks
    )

charts_archive %>% glimpse()

## A one-time write for 02-combine-charts
# charts_archive |> write_csv("data-scraped/billboard-200/previous_archive.csv")
```

## Get recent years

This reads in and combines all the data that I've scraped recently.

### Build a list of files to combine

Right now this would get everything inside `hot100-scraped`, including other yearly folders.

```{r files-list}
#### This requires the fs package
files_list <-  dir_ls("data-download/billboard200-scraped/", recurse = TRUE, regexp = ".csv")

#### A base R version
# files <- list.files(path = "data-download/hot100-scraped/2022/", pattern = "*.csv", full.names = T)

#### Peek at the list
files_list
```

### Combine files in the files_list

Of the many ways to do this, this is the sparsest code. Not sure what I would do if read_csv needed arguments. This uses the tidyverse purrr [map](https://purrr.tidyverse.org/reference/map.html) function.

```{r read-combine-recent}
# uses files_list from above
charts_recent <- map_dfr(files_list, read_csv, col_types = cols("last_week" = col_integer()))
```

Glimpse at the data

```{r recent-glimpse}
charts_recent %>% glimpse()
```

## Bind data sets together

Now to put the archives and recent charts together.

```{r combine-all}
charts_current <- charts_archive %>% 
  bind_rows(charts_recent)

charts_current %>% glimpse()
```


## Export

We'll export these combined files for public use?

```{r export}
charts_current %>% write_csv("data-out/billboard200_current.csv")
```

## Data smells

### Check for 200 records

There are clearly some problems as the number of records is not divisible by 200. The problem is with the older data, but looking into where here.

```{r}
charts_current |> 
  count(chart_week) |> 
  filter(n != 200)
```

The first five that are 175 records seem to match what is online.

- 1967-09-16 is a problem as there are really supposed to be 200. Perhaps we just fix the file?

### Check charts per year

With none below 52 except the first year and current year, I think we are good here. 53 can be OK depending on how the calendar falls.

```{r}
charts_current |> 
  distinct(chart_week) |> 
  count(year(chart_week)) |> 
  filter(n != 52)
```

